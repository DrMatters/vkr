{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './ai-moderator-b18e81abdc4a.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "DICT_SIZE = 10000\n",
    "TEST_SIZE = 10000\n",
    "DEV_SIZE = 10000\n",
    "PATH = '/communities/default/versions/bert/'\n",
    "\n",
    "TRAIN = True\n",
    "UPLOAD = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Make pip python package `GoogleCloudStorageWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import hashlib\n",
    "from os import path\n",
    "\n",
    "from google.api_core import exceptions as g_exceptions\n",
    "from google.cloud import storage as g_storage\n",
    "\n",
    "\n",
    "class GoogleCloudStorageWrapper:\n",
    "    @staticmethod\n",
    "    def md5_base64(filename):\n",
    "        \"\"\"Returns md5 hash with base of 64\"\"\"\n",
    "        hash_md5 = hashlib.md5()\n",
    "        with open(filename, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        hash_md5_base64 = base64.b64encode(hash_md5.digest()).decode('utf-8')\n",
    "        return hash_md5_base64\n",
    "\n",
    "    @staticmethod\n",
    "    def lazy_upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "        \"\"\"Uploads a file to the bucket if it has different hash.\"\"\"\n",
    "        storage_client = g_storage.Client()\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "        remote_blob = bucket.get_blob(destination_blob_name)\n",
    "\n",
    "        local_md5 = GoogleCloudStorageWrapper.md5_base64(source_file_name)\n",
    "\n",
    "        if remote_blob is not None:\n",
    "            remote_md5 = remote_blob.md5_hash\n",
    "            if remote_md5 == local_md5:\n",
    "                print(f'Blob `{destination_blob_name} is '\n",
    "                      f'already in bucket `{bucket_name}`')\n",
    "                return\n",
    "\n",
    "            print(f'Updating blob `{destination_blob_name}` in '\n",
    "                  f'bucket `{bucket_name}` from `{source_file_name}`')\n",
    "\n",
    "        blob.upload_from_filename(source_file_name)\n",
    "\n",
    "        # check for integrity of uploaded file\n",
    "        uploaded_blob = bucket.get_blob(destination_blob_name)\n",
    "        uploaded_md5 = uploaded_blob.md5_hash\n",
    "        if uploaded_md5 != local_md5:\n",
    "            raise g_exceptions.DataLoss('Downloaded file differs from remote')\n",
    "\n",
    "        print(f'File `{source_file_name}` successfully uploaded '\n",
    "              f'to `{destination_blob_name}` of bucket `{bucket_name}`')\n",
    "\n",
    "    @staticmethod\n",
    "    def lazy_download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "        \"\"\"Downloads a blob from the bucket if the local version of file differs\n",
    "        from the remote version (calculated using md5 hash).\"\"\"\n",
    "\n",
    "        storage_client = g_storage.Client()\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(source_blob_name)\n",
    "        remote_blob = bucket.get_blob(source_blob_name)\n",
    "\n",
    "        remote_md5 = remote_blob.md5_hash\n",
    "\n",
    "        if path.exists(destination_file_name):\n",
    "            local_md5 = GoogleCloudStorageWrapper.md5_base64(destination_file_name)\n",
    "            if remote_md5 == local_md5:\n",
    "                print(f'Blob {source_blob_name} is already downloaded to {destination_file_name}')\n",
    "                return\n",
    "\n",
    "        blob.download_to_filename(destination_file_name)\n",
    "\n",
    "        # check for integrity of downloaded file\n",
    "        downloaded_md5 = GoogleCloudStorageWrapper.md5_base64(destination_file_name)\n",
    "        if remote_md5 != downloaded_md5:\n",
    "            raise g_exceptions.DataLoss('Downloaded file differs from remote')\n",
    "\n",
    "        print(f'Blob {source_blob_name} successfully downloaded to {destination_file_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create temporary folder for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./temp-files/'):\n",
    "    os.mkdir('./temp-files/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from google cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleCloudStorageWrapper.lazy_download_blob(bucket_name='communities-models',\n",
    "                                             source_blob_name='/data/toxic-comment/core.csv',\n",
    "                                             destination_file_name='./temp-files/core.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {},
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "core = pd.read_csv(\"./temp-files/core.csv\")\n",
    "core.loc[:, 'comment_text'] = core.loc[:, 'comment_text'].str.lower()\n",
    "core.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = core.assign(len=core['comment_text'].str.len())\n",
    "core.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(core, test_size=(TEST_SIZE + DEV_SIZE), random_state=RANDOM_SEED,\n",
    "                                               stratify=core.loc[:, 'base_class'])\n",
    "dev, test = model_selection.train_test_split(test, test_size=TEST_SIZE, random_state=RANDOM_SEED,\n",
    "                                             stratify=test.loc[:, 'base_class'])\n",
    "print(len(train), len(test), len(dev))\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juicy part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit (and save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    training_successfully_finished = False\n",
    "    # fit your model here\n",
    "    training_successfully_finished = True\n",
    "\n",
    "    if training_successfully_finished:\n",
    "        # Save your model on local drive here:\n",
    "        # Example:\n",
    "        # joblib.dump(tokenizer, './temp-files/tokenizer.joblib')\n",
    "        # model.save(\"./temp-files/model.h5\", overwrite=True)\n",
    "        pass\n",
    "\n",
    "        if UPLOAD:\n",
    "            # Upload your model to cloud here:\n",
    "            # Example:\n",
    "            # GoogleCloudStorageWrapper.lazy_upload_blob(bucket_name='communities-models',\n",
    "            #                                            source_file_name='./temp-files/tokenizer.joblib',\n",
    "            #                                            destination_blob_name=PATH + 'tokenizer.joblib')\n",
    "            # GoogleCloudStorageWrapper.lazy_upload_blob(bucket_name='communities-models',\n",
    "            #                                            source_file_name='./temp-files/model.h5',\n",
    "            #                                            destination_blob_name=PATH + 'model.h5')\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleCloudStorageWrapper.lazy_download_blob(bucket_name='communities-models',\n",
    "                                             source_blob_name=PATH + 'tokenizer.joblib',\n",
    "                                             destination_file_name='./temp-files/tokenizer.joblib')\n",
    "GoogleCloudStorageWrapper.lazy_download_blob(bucket_name='communities-models',\n",
    "                                             source_blob_name=PATH + 'model.h5',\n",
    "                                             destination_file_name='./temp-files/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(\"./temp-files/model.h5\")\n",
    "tokenizer = joblib.load('./temp-files/tokenizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ready = sequence.pad_sequences(\n",
    "    tokenizer.texts_to_sequences(dev['comment_text']), maxlen=MESSAGE_LEN_CHAR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probas = model.predict(dev_ready, verbose=1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = (predicted_probas > 0.5).astype(int)\n",
    "real = dev.loc[:, 'base_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single number metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(predicted, real)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_acc = metrics.balanced_accuracy_score(predicted, real)\n",
    "b_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = metrics.roc_auc_score(real, predicted_probas)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(real, predicted)\n",
    "confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "# cm_df = pd.DataFrame(confusion_matrix, index=[], columns=[])\n",
    "plt.figure(figsize=(8, 6))\n",
    "_ = sns.heatmap(confusion_matrix, cmap='BuGn')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([-0.02, 1.0])\n",
    "    plt.ylim([0.0, 1.02])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds_roc = metrics.roc_curve(real, predicted_probas)\n",
    "plot_roc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prc(precision, recall):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    lw = 2\n",
    "    plt.plot(precision, recall, color='darkorange', lw=lw, label='PR curve')\n",
    "    plt.xlim([0.0, 1.01])\n",
    "    plt.ylim([0.0, 1.02])\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.title('Precision-recall curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, thresholds_prc = metrics.precision_recall_curve(real, predicted_probas)\n",
    "plot_prc(prec, rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
